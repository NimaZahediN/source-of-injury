{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration File Details:**\n",
    "The configuration file (`nz.yml`) specifies the following for the dataset:\n",
    "- **Data Type:** custom, suitable for structured input/output format.\n",
    "- **Tokenizer:** LlamaTokenizer with specific special tokens.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- **Fields:** \"instruction,\" \"input,\" \"output\".\n",
    "- **Example:**\n",
    "  ```json\n",
    "  {\n",
    "      \"instruction\": \"Claim coders manages claims...\",\n",
    "      \"input\": \"IncidentDescription: While working on a vehicle repair...\",\n",
    "      \"output\": \"Reasoning: Contorting the body... - InjurySource: Bodily motion...\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "**Prompt Function:**\n",
    "- Constructs the input using the given `incident_description`.\n",
    "- Example Prompt:\n",
    "  ```plaintext\n",
    "  [INST] <<SYS>>\n",
    "  Medical coders manages claims by reviewing...\n",
    "  <</SYS>>\n",
    "\n",
    "  IncidentDescription: {incident_description}\n",
    "  [/INST]\n",
    "  ```\n",
    "\n",
    "### Validation Steps:\n",
    "\n",
    "1. **Check Data Type Compatibility:**\n",
    "   Ensure the dataset format matches the configuration expectations. The \"custom\" type indicates a tailored structure for specific fields.\n",
    "   ```yaml\n",
    "   data_type: \"custom\"\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    with open('synthec_data.json') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        assert 'instruction' in entry, f\"Missing 'instruction' in entry {i}\"\n",
    "        assert 'input' in entry, f\"Missing 'input' in entry {i}\"\n",
    "        assert 'output' in entry, f\"Missing 'output' in entry {i}\"\n",
    "    \n",
    "    print(\"All entries have 'instruction', 'input', and 'output'.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"AssertionError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Validator\n",
    "\n",
    "Verifying that the constructed prompt matches the expected input during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the constructed prompt matches the expected input during fine-tuning.\n",
    "def prompt(incident_description):\n",
    "    return f\"\"\"[INST] <<SYS>>\n",
    "    Workers Compensation Board manages claims...\n",
    "    <</SYS>>\n",
    "\n",
    "    IncidentDescription: {incident_description}\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "   \n",
    "sample_incident = \"While working on a vehicle repair...\"\n",
    "sample_prompt = prompt(sample_incident)\n",
    "print(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Ensure the model correctly processes the structured input and provides the expected output.\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = 'NimaZahedinameghi/source_of_injury'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "input_text = prompt(\"While working on a vehicle repair...\")\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "outputs = model.generate(**inputs)\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
