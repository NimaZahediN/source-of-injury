{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration File Details:**\n",
    "The configuration file (`nz.yml`) specifies the following for the dataset:\n",
    "- **Data Type:** custom, suitable for structured input/output format.\n",
    "- **Tokenizer:** LlamaTokenizer with specific special tokens.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- **Fields:** \"instruction,\" \"input,\" \"output\".\n",
    "- **Example:**\n",
    "  ```json\n",
    "  {\n",
    "      \"instruction\": \"Claim coders manages claims...\",\n",
    "      \"input\": \"IncidentDescription: While working on a vehicle repair...\",\n",
    "      \"output\": \"Reasoning: Contorting the body... - InjurySource: Bodily motion...\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "**Prompt Function:**\n",
    "- Constructs the input using the given `incident_description`.\n",
    "- Example Prompt:\n",
    "  ```plaintext\n",
    "  [INST] <<SYS>>\n",
    "  Medical coders manages claims by reviewing...\n",
    "  <</SYS>>\n",
    "\n",
    "  IncidentDescription: {incident_description}\n",
    "  [/INST]\n",
    "  ```\n",
    "\n",
    "### Validation Steps:\n",
    "\n",
    "1. **Check Data Type Compatibility:**\n",
    "   Ensure the dataset format matches the configuration expectations. The \"custom\" type indicates a tailored structure for specific fields.\n",
    "   ```yaml\n",
    "   data_type: \"custom\"\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    with open('synthec_data.json') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        assert 'instruction' in entry, f\"Missing 'instruction' in entry {i}\"\n",
    "        assert 'input' in entry, f\"Missing 'input' in entry {i}\"\n",
    "        assert 'output' in entry, f\"Missing 'output' in entry {i}\"\n",
    "    \n",
    "    print(\"All entries have 'instruction', 'input', and 'output'.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"AssertionError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Validator\n",
    "\n",
    "Verifying that the constructed prompt matches the expected input during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "# Test tokenization consistency\n",
    "tokens1 = tokenizer(prompt(incident_description), return_tensors=\"pt\").input_ids\n",
    "tokens2 = tokenizer(prompt(incident_description), return_tensors=\"pt\").input_ids\n",
    "assert torch.equal(tokens1, tokens2), \"Tokenization is inconsistent\"\n",
    "\n",
    "# Test inference consistency\n",
    "output1 = prompt_tok(incident_description)\n",
    "output2 = prompt_tok(incident_description)\n",
    "assert output1 == output2, \"Inference is inconsistent\"\n",
    "\n",
    "# Test format validation\n",
    "def validate_output_format(output):\n",
    "    reasoning_pattern = r\"Reasoning: .+ - InjurySource: .+\"\n",
    "    match = re.search(reasoning_pattern, output)\n",
    "    assert match, \"Output format is incorrect\"\n",
    "\n",
    "output = prompt_tok(incident_description)\n",
    "validate_output_format(output)\n",
    "\n",
    "# Test token length\n",
    "input_ids = tokenizer(prompt(incident_description), return_tensors=\"pt\").input_ids\n",
    "assert input_ids.size(1) <= model.config.max_position_embeddings, \"Input token length exceeds the limit\"\n",
    "\n",
    "# Performance test with sample data\n",
    "test_cases = [\n",
    "    \"While working on a vehicle repair, I had to contort my body...\",\n",
    "    \"I was struck by a low-hanging branch from a tree...\"\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    output = prompt_tok(case)\n",
    "    validate_output_format(output)\n",
    "    print(output)\n",
    "\n",
    "# Stress test with edge cases\n",
    "edge_cases = [\n",
    "    \"\",  # Empty input\n",
    "    \"a\" * 1000,  # Very long input\n",
    "    \"The quick brown fox jumps over the lazy dog\",  # General non-related text\n",
    "]\n",
    "\n",
    "for case in edge_cases:\n",
    "    output = prompt_tok(case)\n",
    "    validate_output_format(output)\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
